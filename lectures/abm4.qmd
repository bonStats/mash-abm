---
title: "Bayesian workflow and Stan"
subtitle: "Applied Bayesian Modelling: Section 4"
author: "Dr Joshua J Bon"
bibliography: ../assets/refs.bib
format:
  revealjs:
    html-math-method: katex
    theme: default
    df-print: paged
    incremental: false 
    css: style.css
    chalkboard: true
    logo: ../assets/dauphine-logo-white.png
    footer: "[:arrow_up: ABM](../index.qmd)"
    cache: true
editor: source
from: markdown+emoji
---

{{< include ../snippets/_data-directory.qmd >}}

## Applied Bayesian modelling

-   Statistical inference :mag:
-   Statistical prediction 
-   Bayesian models
-   Computation :mag:
-   Workflows :mag:

# Statistical inference

## Example 4: ???


```{r X-plot}
#| echo: true
#| code-fold: true



```

## What have we seen so far?

- Bayesian modelling
    - Building a model of the data
    - Choosing a prior distribution
    - Model selection

- Bayesian computation
    - Conjugate priors
    - MCMC: MH and Gibbs
    - MCMC diagnostics
    
## A simplified Bayesian workflow

<br>

```{mermaid}
%%| fig-align: center
flowchart TD
  B(Build Bayesian model) --> C(Compute posterior)
  C --> E(Evaluate posterior)
  E --> I[Conclusions]
  C -.-> B
  E -.-> B
  I --> Inf(Inference)
  I --> Pred(Prediction)
  I --> Dec(Decisions)
```

## A simplified Bayesian workflow

<br>

:::: {.columns}

::: {.column width="38%"}


#### Overall workflow

```{mermaid}
flowchart TD
  B(Build Bayesian model) --> C(Compute posterior)
  C --> E(Evaluate posterior)
  E --> I[Conclusions]
  C -.-> B
  E -.-> B
```

@gelman2020bayesian

:::

::: {.column width="5%"}

:::

::: {.column width="57%"}

#### Build Bayesian model
```{mermaid}
flowchart LR
  A(Propose likelihood) --> B( Propose prior)
  B --> C(Validate prior)
  C -.-> B
  C -.-> A
```

#### Compute posterior
```{mermaid}
flowchart LR
  A(Choose tool and settings) --> B(Fit model)
  B --> C(Validate approximation)
  C -.-> A
```

#### Evaluate posterior
```{mermaid}
flowchart LR
  A(Model checking) --> B(Model comparison)
  B --> C(Model choice)
```
:::

::::

## Build Bayesian model

<br> 

:::: {.columns}

::: {.column width="70%"}

#### Propose likelihood

How are the data generated?

- Support of distribution
- Dependency between data

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Propose likelihood) --> B( Propose prior)
  B --> C(Validate prior)
  C -.-> B
  C -.-> A
```

:::

::::

## Build Bayesian model

<br> 

:::: {.columns}

::: {.column width="70%"}

#### Propose prior

What prior information do we have on the model parameters (given the likelihood)?

- Global vs local parameters
- Constraints
- Expert elicitation

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Propose likelihood) --> B( Propose prior)
  B --> C(Validate prior)
  C -.-> B
  C -.-> A
```

:::

::::

## Build Bayesian model

<br> 

:::: {.columns}

::: {.column width="70%"}

#### Validate prior

Does the prior predictive distribution produce data that is reasonable?

- Prior predictive checking
- Domain knowledge

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Propose likelihood) --> B( Propose prior)
  B --> C(Validate prior)
  C -.-> B
  C -.-> A
```

:::

::::

## Compute posterior

<br> 

:::: {.columns}

::: {.column width="70%"}

#### Choose tool and settings

- Conjugate prior
- MC algorithm: MH, Gibbs, HMC^[Continuous parameters]
- MCMC settings: proposal distribution

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Choose tool and settings) --> B(Fit model)
  B --> C(Validate approximation)
  C -.-> A
```

:::

::::


## Compute posterior

<br> 

:::: {.columns}

::: {.column width="70%"}

#### Fit model

- MCMC software: R, Stan
- Initial number of iterations
- Save samples

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Choose tool and settings) --> B(Fit model)
  B --> C(Validate approximation)
  C -.-> A
```

:::

::::


## Compute posterior

<br> 

:::: {.columns}

::: {.column width="70%"}

#### Validate approximation

- Convergence diagnostics: $\hat{R}$, ESS
- Visualisations: Trace, autocorrelation plots

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Choose tool and settings) --> B(Fit model)
  B --> C(Validate approximation)
  C -.-> A
```

:::

::::


##

### The folk theorem of statistical computing

<br>

:::: {.columns}

::: {.column width="70%"}

When you have computational problems, often thereâ€™s a problem with your model 

-@yao2022stacking

:::

::: {.column width="30%"}

```{mermaid}
%%| fig-align: right
flowchart TD
  B(Build Bayesian model) --> C(Compute posterior)
  C --> E(Evaluate posterior)
  E --> I[Conclusions]
  C -.-> B
  E -.-> B
  
  linkStyle 3 stroke-width:4px, stroke:red
```

:::

::::

## Evaluate posterior

<br>

:::: {.columns}

::: {.column width="70%"}

#### Model checking

- Posterior predictive
- Inflence of prior

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Model checking) --> B(Model comparison)
  B --> C(Model choice)
```

:::

::::

## Evaluate posterior

<br>

:::: {.columns}

::: {.column width="70%"}

#### Model comparison

- Model evidence
- Cross validation

:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Model checking) --> B(Model comparison)
  B --> C(Model choice)
```

:::

::::

## Evaluate posterior

<br>

:::: {.columns}

::: {.column width="70%"}

#### Model choice

- Model selection
- Model averaging
- Posterior stacking [@yao2018using]


:::

::: {.column width="30%"}

```{mermaid}
flowchart TD
  A(Model checking) --> B(Model comparison)
  B --> C(Model choice)
```

:::

::::

# PPLs and Stan

## Probabilistic programming languages

- Syntax to encode joint probability model
- Creates joint probability object to be queried

```{mermaid}
%%| fig-align: center
flowchart LR
  A(PPL model specification) --> B(Joint probability object)
  B --> C(Inference algorithms)
```

PPLs are usually bundled with inference algorithm(s)

- MCMC (HMC!)
- VI
- SMC

## PPL examples

| Name                                 | PPL lang.            | Inference lang.      | Backend              |
|--------------------------------------|----------------------|----------------------|----------------------|
| BUGS family^[BUGS, WinBugs, OpenBUGS, JAGS]                         | "BUGS"               | various              |  various          |
| [Stan](https://mc-stan.org)          | Stan                 | R, Python, Julia,... | C++                  |
| [Turing.jl](https://turinglang.org)  | Julia                | Julia                | Julia
| [Pyro](http://pyro.ai)^[See also [numPyro](https://num.pyro.ai/) using JAX backend] | Python | Python | PyTorch |
| [PyMC](https://www.pymc.io/)         | Python               | Python               | PyTensor |
| [greta](https://greta-stats.org)     | R                    | R                    | TensorFlow |


## Bayesian models in Stan

:::: {.columns}

::: {.column width="40%"}

#### Probability model

Prior

$\alpha \sim \mathcal{N}(0,1)$

$\beta \sim \mathcal{N}(0,1)$
 
$\sigma \sim\mathcal{IG}(1,1)$

Likelihood 

$y_i \mid \alpha,\beta,\sigma, x \overset{\text{iid}}{\sim} \mathcal{N}(\alpha+\beta x_i,\sigma^2)$

:::

::: {.column width="60%"}

#### Stan code

```stan
data {
  int<lower=0> N;
  vector[N] x;
  vector[N] y;
}
parameters {
  real alpha;
  real beta;
  real<lower=0> sigma;
}
model {
  // prior
  alpha ~ normal(0, 1);
  beta ~ normal(0, 1);
  sigma ~ inv_gamma(1, 1);
  // likelihood
  y ~ normal(alpha + beta * x, sigma);
}
```

:::

::::

## Joint probaility object

```{mermaid}
%%| fig-align: center
flowchart LR
  A(Joint probability object)
  A --> C(Prior)
  C -.-> CA(log-prior density)
  A --> E(Data process)
  C --> F(Prior predictive)
  E --> F
  
  
  CA -.-> DA(unnormalised log-posterior density)
  E -.-> EA(log-likelihood)
  EA -.-> DA
```

$$\pi(\theta\mid y) \propto p(y, \theta) = p(y\mid\theta)\pi(\theta)$$

## Stan in R

Build, run model


## Crash-course in HMC

Hamiltonian Monte Carlo



## References

::: {#refs}
:::

# Appendices




